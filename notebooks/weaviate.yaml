---
services:
  weaviate:
    command:
    - --host
    - 0.0.0.0
    - --port
    - '8080'
    - --scheme
    - http
    image: cr.weaviate.io/semitechnologies/weaviate:1.28.2
    ports:
    - 8080:8080
    - 50051:50051
    volumes:
    - ./weaviate_data:/var/lib/weaviate
    restart: on-failure:0
    environment:
      TRANSFORMERS_INFERENCE_API: 'http://t2v-transformers:8080'
      #QNA_INFERENCE_API: 'http://qna-transformers:8080'
      #NER_INFERENCE_API: 'http://ner-transformers:8080'
      AUTOSCHEMA_ENABLED: 'false'
      QUERY_DEFAULTS_LIMIT: 5
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'text2vec-transformers'
      ENABLE_MODULES: 'text2vec-transformers' #,qna-transformers,ner-transformers'
      CLUSTER_HOSTNAME: 'node1'
  t2v-transformers:
    image: cr.weaviate.io/semitechnologies/transformers-inference:baai-bge-m3-onnx # CPU Optimized Multilanguage
    environment:
      ENABLE_CUDA: '0' # You can set to 1 to use the GPU. Don't forget to change the t2v transformers model as well (we are using the CPU optim)
  # qna-transformers:
  #   image: cr.weaviate.io/semitechnologies/qna-transformers:distilbert-base-uncased-distilled-squad
  #   environment:
  #     ENABLE_CUDA: '0'
  # ner-transformers:
  #   image: cr.weaviate.io/semitechnologies/ner-transformers:dbmdz-bert-large-cased-finetuned-conll03-english
  #   environment:
  #     ENABLE_CUDA: '0'